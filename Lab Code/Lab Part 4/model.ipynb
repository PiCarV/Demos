{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Part 4\n",
    "# Neural Network Model Template\n",
    "\n",
    "#\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Define where we store our data\n",
    "This is pretty simple our folder structure looks like this\n",
    "- data/\n",
    "    - train/\n",
    "    - test/\n",
    "\n",
    "So we simply create 2 variables to store these locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/' # change this to your data directory\n",
    "train_dir = data_dir + 'train/' # directory for training images\n",
    "test_dir = data_dir + 'test/' # directory for test images we use the test images to make sure our model is working well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Loading in the data\n",
    "### Dealing with images\n",
    "Our image files that we are using for training are pretty large. Your computer may crash if we loaded them all at once so instead we will just store where the images are stored. Later you will see how we can automatically load these files when we run our code. One thing to note is that each image file is named (somenumber).jpg that number is the number of milliseconds since 1 January 1970 (Unix Time) when the file was recorded. This means that we will never have any overlapping files. Unfortunately this does mean we will have to sort the times from smallest to largest to make sure that they correspond with the steering angles.\n",
    "\n",
    "### Dealing with steering angles\n",
    "We store our steering values as a csv (comma separated values) file. Python has a built in csv module so we can easily use it to load in all the steering values into a list. These don't take up much ram so it doesn't matter if we load them all in at once.\n",
    "\n",
    "### Making sure the files line up\n",
    "Since we sort our images, and the csv file is read in line by line the files will line up with their correct steering angles. It looks something like this. If we mess this up then the data being fed into your network would be totally incoherent. Garbage in Garbage out.\n",
    "\n",
    "train_img =   | image 1    | image 2    | image 3    | image 4    | image 5    |...\n",
    "\n",
    "train_steer = | steering 1 | steering 2 | steering 3 | steering 4 | steering 5 |..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "# lets make a function that loads the images and labels\n",
    "def load_data(directory):\n",
    "    image__paths = []\n",
    "    csv_file = \"\"\n",
    "    for file in os.listdir(directory): # for each file in the directory\n",
    "        if file.endswith(\".jpg\"): # if the file is an image\n",
    "            image__paths.append(directory + file) # add the image path to the list\n",
    "        if file.endswith(\".csv\"): # if the file is a csv file\n",
    "            csv_file = file # we save it for later\n",
    "\n",
    "    # now our files are in the train list we need to sort them from smallest file name to largest. The file name is the exact time the image was taken.\n",
    "    image__paths.sort(key=lambda x: int(x.split('/')[-1][:-4])) # the lambda function returns the numbers in the file name\n",
    "\n",
    "    # now we need to read the csv file and get the steering angles\n",
    "    with open(directory + csv_file, 'r') as f:\n",
    "        reader = csv.reader(f) # create a reader object\n",
    "        steering_angles = [] # create a list to store the steering angles\n",
    "        for row in reader: # for each row in the csv file\n",
    "            steering_angles.append(float(row[0])) # add the steering angle to the list\n",
    "    return image__paths, steering_angles # return the image paths and steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, train_steer = load_data(train_dir) # load the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Loading the images on the fly\n",
    "\n",
    "Now we create a data generator that automatically fetches the images when we need it.\n",
    "This generator will also apply our image processing that we learnt about in our last lab.\n",
    "This generator takes in a batch_size which means we can increase or decrease the amount of data returned based on how much RAM our computer has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "def batch_generator(image_paths, steering_angles, batch_size):\n",
    "    while True:\n",
    "        for start in range(0, len(image_paths), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(image_paths))\n",
    "            ids_batch = image_paths[start:end]\n",
    "            for id in ids_batch:\n",
    "                img = cv.imread(id)\n",
    "                img = cv.resize(img, (100, 66))\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(steering_angles[image_paths.index(id)])\n",
    "            x_batch = np.array(x_batch, np.float32)\n",
    "            y_batch = np.array(y_batch, np.float32)\n",
    "            yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: This is where you will create your model\n",
    "try modifying the layers to try to get the lowest mse score,\n",
    "This is going to require some trial and error so make sure you spend some time experimenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5/5 [==============================] - 1s 67ms/step - loss: 10489.0049\n",
      "Epoch 2/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 8783.3252\n",
      "Epoch 3/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 7340.7886\n",
      "Epoch 4/25\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 6068.4614\n",
      "Epoch 5/25\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 5009.4741\n",
      "Epoch 6/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 4129.6631\n",
      "Epoch 7/25\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 3374.8501\n",
      "Epoch 8/25\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 2797.7703\n",
      "Epoch 9/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 2465.3472\n",
      "Epoch 10/25\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 2349.3149\n",
      "Epoch 11/25\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 2359.5649\n",
      "Epoch 12/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 2395.0208\n",
      "Epoch 13/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 2406.8135\n",
      "Epoch 14/25\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2392.8730\n",
      "Epoch 15/25\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 2373.7883\n",
      "Epoch 16/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 2360.7510\n",
      "Epoch 17/25\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 2353.6404\n",
      "Epoch 18/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 2349.6443\n",
      "Epoch 19/25\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2346.8062\n",
      "Epoch 20/25\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2344.7808\n",
      "Epoch 21/25\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 2342.8848\n",
      "Epoch 22/25\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2341.1895\n",
      "Epoch 23/25\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2339.1497\n",
      "Epoch 24/25\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2335.9922\n",
      "Epoch 25/25\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 2334.6672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f75e2c0b80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer\n",
    "\n",
    "# a sequential model is a model that is made up of layers\n",
    "model = Sequential()\n",
    "# the input layer is the first layer in the model\n",
    "model.add(InputLayer(input_shape=(100, 66, 3)))\n",
    "\n",
    "# try modifying the number of nodes in the hidden layer to see how it affects the model\n",
    "# you can also try changing the activation function to see how it affects the model\n",
    "# adding more layers to the model may also help\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1 ,activation='linear'))\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(batch_generator(train_img, train_steer, batch_size), steps_per_epoch=np.ceil(float(len(train_img)) / float(batch_size)), epochs=25) # changing the number of epochs may help the model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b8c902a5db4bd22b43399a271754202218dc4d05c7622b2f621f708dd6b6e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
